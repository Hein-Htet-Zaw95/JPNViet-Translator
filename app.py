import io
import os
import time
import tempfile
from typing import Literal

import streamlit as st
from dotenv import load_dotenv
from langdetect import detect
from audio_recorder_streamlit import audio_recorder
from openai import OpenAI
from pydub import AudioSegment

# -----------------------------
# åˆæœŸåŒ–
# -----------------------------
load_dotenv()
if "OPENAI_API_KEY" not in os.environ or not os.environ["OPENAI_API_KEY"].strip():
    st.warning("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ .env ã«è¿½åŠ ã—ã¦ãã ã•ã„ã€‚")

client = OpenAI()

APP_TITLE = "ğŸ‡»ğŸ‡³â‡„ğŸ‡¯ğŸ‡µ ãƒ™ãƒˆãƒŠãƒ èª â‡„ æ—¥æœ¬èª ç¿»è¨³ (ãƒ†ã‚­ã‚¹ãƒˆ + éŸ³å£°)"
STT_MODEL = "gpt-4o-mini-transcribe"     # éŸ³å£°â†’ãƒ†ã‚­ã‚¹ãƒˆ
TTS_MODEL = "gpt-4o-mini-tts"             # ãƒ†ã‚­ã‚¹ãƒˆâ†’éŸ³å£°
LLM_MODEL = "gpt-4o-mini"                 # ç¿»è¨³

st.set_page_config(page_title=APP_TITLE, page_icon="ğŸŒ", layout="centered")
st.title(APP_TITLE)
st.caption("ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³ã€ãƒã‚¤ã‚¯å…¥åŠ›ã€éŸ³å£°ä¼šè©±ã€‚Streamlit + OpenAI ã§æ§‹ç¯‰ã€‚")

# -----------------------------
# ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# -----------------------------

def detect_lang_simple(text: str) -> str:
    """ãƒ™ãƒˆãƒŠãƒ èª/æ—¥æœ¬èªã®ç°¡æ˜“åˆ¤å®š"""
    if any("ã€" <= ch <= "ãƒ¿" or "ä¸€" <= ch <= "é¿¿" for ch in text):
        return "ja"
    try:
        lang = detect(text)
        if lang in ("ja", "vi"):
            return lang
    except Exception:
        pass
    return "vi" if all(ord(c) < 128 for c in text) else "ja"


def translate_text(text: str, src: str, dst: str) -> str:
    if src == "auto":
        detected = detect_lang_simple(text)
        if detected in ("vi", "ja"):
            src = detected
        else:
            src = "vi"  # default fallback
    if src == dst:
        return text

    system_prompt = (
        "ã‚ãªãŸã¯ãƒ—ãƒ­ã®ç¿»è¨³è€…ã§ã™ã€‚æ–‡ç« ã‚’ç°¡æ½”ã‹ã¤è‡ªç„¶ã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"
        "- ã‚½ãƒ¼ã‚¹è¨€èª: 'vi'=ãƒ™ãƒˆãƒŠãƒ èª, 'ja'=æ—¥æœ¬èª"
        "- ã‚¿ãƒ¼ã‚²ãƒƒãƒˆè¨€èª: 'ja'=æ—¥æœ¬èª, 'vi'=ãƒ™ãƒˆãƒŠãƒ èª"
        "- æ•°å­—ã‚„åå‰ã¯ãã®ã¾ã¾ä¿æŒ"
        "- èª¬æ˜ã¯è¿½åŠ ã›ãšç¿»è¨³æ–‡ã®ã¿å‡ºåŠ›"
    )

    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"[SRC={src}] [DST={dst}]\n{text}"},
    ]

    try:
        resp = client.chat.completions.create(
            model=LLM_MODEL,
            messages=messages,  # type: ignore
            temperature=0.2,
        )
        return resp.choices[0].message.content.strip() if resp.choices[0].message.content else "Translation failed"
    except Exception as e:
        return f"Translation error: {str(e)}"


def transcribe_bytes(wav_bytes: bytes, lang_hint: str = "auto") -> str:
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
        tmp.write(wav_bytes)
        tmp_path = tmp.name
    try:
        with open(tmp_path, "rb") as f:
            kwargs = {"model": STT_MODEL, "file": f}
            if lang_hint in ("vi", "ja"):
                kwargs["language"] = lang_hint
            stt = client.audio.transcriptions.create(**kwargs)
        return stt.text.strip()
    finally:
        try:
            os.remove(tmp_path)
        except OSError:
            pass


def speak(text: str, voice: str = "alloy", fmt: str = "mp3"):
    """TTSï¼ˆformat å¼•æ•°ãªã—ï¼‰ã€‚å¿…è¦ãªã‚‰ãƒ­ãƒ¼ã‚«ãƒ«ã§ MP3â†’WAV å¤‰æ›ã€‚æˆ»ã‚Šå€¤ã¯ (bytes, mime)ã€‚"""
    if not text.strip():
        return b"", "audio/mp3"

    # æ–°SDKã§ã¯ format= ã¯ä½¿ã‚ãªã„
    resp = client.audio.speech.create(
        model=TTS_MODEL,
        voice=voice,
        input=text,
    )
    raw = resp.read()  # bytesï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ MP3 ãƒ‡ãƒ¼ã‚¿ï¼‰

    if fmt == "mp3":
        return raw, "audio/mp3"

    # WAV ãŒé¸æŠã•ã‚ŒãŸå ´åˆã¯ãƒ­ãƒ¼ã‚«ãƒ«å¤‰æ›
    try:
        seg = AudioSegment.from_file(io.BytesIO(raw), format="mp3")
        buf = io.BytesIO()
        seg.export(buf, format="wav")
        return buf.getvalue(), "audio/wav"
    except Exception:
        # å¤‰æ›å¤±æ•—æ™‚ã¯ MP3 ã‚’è¿”ã™
        return raw, "audio/mp3"

# -----------------------------
# UI ã‚µã‚¤ãƒ‰ãƒãƒ¼
# -----------------------------
with st.sidebar:
    st.header("âš™ï¸ è¨­å®š / CÃ i Ä‘áº·t")
    mode = st.radio("ãƒ¢ãƒ¼ãƒ‰ / Cháº¿ Ä‘á»™", ["ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³ / Dá»‹ch vÄƒn báº£n", "éŸ³å£°å…¥åŠ› / Ghi Ã¢m", "ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ / Há»™i thoáº¡i"], index=0) or "ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³ / Dá»‹ch vÄƒn báº£n"
    st.divider()
    st.subheader("ç¿»è¨³è¨­å®š / Cáº¥u hÃ¬nh dá»‹ch")
    col1, col2 = st.columns(2)
    with col1:
        src_choice = st.selectbox("å…¥åŠ›è¨€èª / NgÃ´n ngá»¯ nguá»“n", ["auto", "vi", "ja"], index=0) or "auto"
    with col2:
        dst_choice = st.selectbox("å‡ºåŠ›è¨€èª / NgÃ´n ngá»¯ Ä‘Ã­ch", ["ja", "vi"], index=0) or "ja"
    st.caption("Tip: 'auto'=è‡ªå‹•åˆ¤å®š / tá»± Ä‘á»™ng phÃ¡t hiá»‡n")

    st.divider()
    st.subheader("éŸ³å£°è¨­å®š / Cáº¥u hÃ¬nh giá»ng nÃ³i")
    tts_voice = st.selectbox("éŸ³å£°ã‚¿ã‚¤ãƒ— / Giá»ng", ["alloy", "verse", "aria", "sage"], index=0) or "alloy"
    audio_format = st.selectbox("éŸ³å£°å½¢å¼ / Äá»‹nh dáº¡ng", ["mp3", "wav"], index=0) or "mp3"

# -----------------------------
# å„ãƒ¢ãƒ¼ãƒ‰ (UI è¡¨ç¤ºã‚‚æ—¥è¶Šä½µè¨˜)
# -----------------------------
if mode.startswith("ãƒ†ã‚­ã‚¹ãƒˆ"):
    st.subheader("ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆç¿»è¨³ / Dá»‹ch vÄƒn báº£n")
    example = "Xin chÃ o, ráº¥t vui Ä‘Æ°á»£c gáº·p báº¡n." if dst_choice == "ja" else "ä»Šæ—¥ã¯ã¨ã¦ã‚‚æš‘ã„ã§ã™ã­ã€‚"
    text_in = st.text_area("ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ› / Nháº­p vÄƒn báº£n", example, height=150)
    if st.button("ç¿»è¨³ / Dá»‹ch", type="primary"):
        if not text_in.strip():
            st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ / Vui lÃ²ng nháº­p vÄƒn báº£n")
        else:
            with st.spinner("ç¿»è¨³ä¸­... / Äang dá»‹ch..."):
                out = translate_text(text_in, src_choice, dst_choice)
            st.success("å®Œäº† / HoÃ n táº¥t")
            st.markdown("**ç¿»è¨³çµæœ / Káº¿t quáº£**")
            st.text_area("", out, height=150)
            audio_bytes, mime = speak(out, voice=tts_voice, fmt=audio_format)
            if audio_bytes:
                st.audio(audio_bytes, format=mime)

elif mode.startswith("éŸ³å£°å…¥åŠ›"):
    st.subheader("ğŸ¤ éŸ³å£°å…¥åŠ›ç¿»è¨³ / Dá»‹ch giá»ng nÃ³i")
    st.caption("ã‚¯ãƒªãƒƒã‚¯ã—ã¦éŒ²éŸ³ / Nháº¥n Ä‘á»ƒ ghi Ã¢m")

    wav_bytes = audio_recorder(text="éŒ²éŸ³ / Ghi Ã¢m", recording_color="#e53935", neutral_color="#6c757d", icon_size="2x")
    if wav_bytes:
        st.info("éŒ²éŸ³å®Œäº† / ÄÃ£ ghi Ã¢m. ãƒ†ã‚­ã‚¹ãƒˆåŒ–ä¸­... / Äang nháº­n dáº¡ng...")
        transcript = transcribe_bytes(wav_bytes, src_choice if src_choice != "auto" else "auto")
        st.markdown("**æ–‡å­—èµ·ã“ã— / VÄƒn báº£n**")
        st.write(transcript)

        with st.spinner("ç¿»è¨³ä¸­... / Äang dá»‹ch..."):
            out = translate_text(transcript, src_choice, dst_choice)
        st.markdown("**ç¿»è¨³ / Báº£n dá»‹ch**")
        st.write(out)

        audio_bytes, mime = speak(out, voice=tts_voice, fmt=audio_format)
        if audio_bytes:
            st.audio(audio_bytes, format=mime)

elif mode.startswith("ä¼šè©±"):
    st.subheader("ğŸ—£ï¸ ä¼šè©±ãƒ¢ãƒ¼ãƒ‰ / Há»™i thoáº¡i")
    st.caption("äº¤äº’ã«è©±ã—ã¦ãã ã•ã„ / NÃ³i láº§n lÆ°á»£t")

    if "chat" not in st.session_state:
        st.session_state.chat = []

    wav_bytes = audio_recorder(text="è©±ã™ / NÃ³i", recording_color="#1e88e5", neutral_color="#6c757d", icon_size="2x")
    if wav_bytes:
        transcript = transcribe_bytes(wav_bytes, "auto")
        detected = detect_lang_simple(transcript)
        target = "ja" if detected == "vi" else "vi"
        translation = translate_text(transcript, detected, target)
        st.session_state.chat.append({
            "speaker": "A" if (len(st.session_state.chat) % 2 == 0) else "B",
            "transcript": transcript,
            "translation": translation,
            "src": detected,
            "dst": target,
        })
        audio_bytes, mime = speak(translation, voice=tts_voice, fmt=audio_format)
        if audio_bytes:
            st.audio(audio_bytes, format=mime)

    for i, msg in enumerate(reversed(st.session_state.chat)):
        role = msg["speaker"]
        st.markdown(f"### {len(st.session_state.chat)-i} å›ç›® / LÆ°á»£t {len(st.session_state.chat)-i} Â· è©±è€… / NgÆ°á»i nÃ³i {role}")
        st.markdown(f"**åŸæ–‡ ({msg['src']})**: {msg['transcript']}")
        st.markdown(f"**ç¿»è¨³ ({msg['dst']})**: {msg['translation']}")
        st.divider()

# -----------------------------
# Footer
# -----------------------------
st.caption("â¤ï¸ Streamlit + OpenAI ã§æ§‹ç¯‰ Â· XÃ¢y dá»±ng báº±ng Streamlit vÃ  OpenAI Â· FFmpeg æ¨å¥¨ / NÃªn cÃ i FFmpeg")